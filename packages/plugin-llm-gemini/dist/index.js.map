{"version":3,"sources":["../src/index.ts"],"sourcesContent":["import { z } from \"zod\";\nimport type {\n  PluginContract,\n  PluginResourceConstraints,\n  PluginValidationResult,\n  PluginExecuteContext,\n  PluginExecuteOptions,\n  PluginExecuteResult,\n  PluginUsageMetrics,\n  PluginMappedError,\n} from \"@glueco/shared\";\nimport { createPluginBase } from \"@glueco/shared\";\n\n// ============================================\n// GEMINI LLM PLUGIN\n// Accepts OpenAI-compatible requests, translates to Gemini API\n// ============================================\n\nconst GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta\";\n\n// Default allowed models if not specified in constraints\nconst DEFAULT_GEMINI_MODELS = [\n  \"gemini-2.0-flash-exp\",\n  \"gemini-1.5-flash\",\n  \"gemini-1.5-flash-8b\",\n  \"gemini-1.5-pro\",\n];\n\n// ============================================\n// REQUEST SCHEMA (OpenAI-compatible)\n// ============================================\n\nconst ChatMessageSchema = z.object({\n  role: z.enum([\"system\", \"user\", \"assistant\", \"tool\"]),\n  content: z\n    .union([\n      z.string(),\n      z.array(\n        z.object({\n          type: z.string(),\n          text: z.string().optional(),\n          image_url: z\n            .object({\n              url: z.string(),\n              detail: z.string().optional(),\n            })\n            .optional(),\n        })\n      ),\n    ])\n    .nullable(),\n  name: z.string().optional(),\n  tool_calls: z\n    .array(\n      z.object({\n        id: z.string(),\n        type: z.literal(\"function\"),\n        function: z.object({\n          name: z.string(),\n          arguments: z.string(),\n        }),\n      })\n    )\n    .optional(),\n  tool_call_id: z.string().optional(),\n});\n\nconst ChatCompletionRequestSchema = z.object({\n  model: z.string(),\n  messages: z.array(ChatMessageSchema),\n  temperature: z.number().min(0).max(2).optional(),\n  top_p: z.number().min(0).max(1).optional(),\n  n: z.number().int().min(1).max(10).optional(),\n  stream: z.boolean().optional(),\n  stop: z.union([z.string(), z.array(z.string())]).optional(),\n  max_tokens: z.number().int().positive().optional(),\n  max_completion_tokens: z.number().int().positive().optional(),\n  presence_penalty: z.number().min(-2).max(2).optional(),\n  frequency_penalty: z.number().min(-2).max(2).optional(),\n  logit_bias: z.record(z.number()).optional(),\n  user: z.string().optional(),\n  tools: z\n    .array(\n      z.object({\n        type: z.literal(\"function\"),\n        function: z.object({\n          name: z.string(),\n          description: z.string().optional(),\n          parameters: z.record(z.unknown()).optional(),\n        }),\n      })\n    )\n    .optional(),\n  tool_choice: z\n    .union([\n      z.literal(\"none\"),\n      z.literal(\"auto\"),\n      z.literal(\"required\"),\n      z.object({\n        type: z.literal(\"function\"),\n        function: z.object({ name: z.string() }),\n      }),\n    ])\n    .optional(),\n  response_format: z\n    .object({\n      type: z.enum([\"text\", \"json_object\"]),\n    })\n    .optional(),\n  seed: z.number().int().optional(),\n});\n\ntype ChatCompletionRequest = z.infer<typeof ChatCompletionRequestSchema>;\n\n// ============================================\n// FORMAT CONVERSION\n// ============================================\n\ninterface GeminiContent {\n  role: \"user\" | \"model\";\n  parts: Array<\n    { text: string } | { inlineData: { mimeType: string; data: string } }\n  >;\n}\n\ninterface GeminiRequest {\n  contents: GeminiContent[];\n  systemInstruction?: { parts: Array<{ text: string }> };\n  generationConfig?: {\n    temperature?: number;\n    topP?: number;\n    maxOutputTokens?: number;\n    stopSequences?: string[];\n  };\n}\n\nfunction convertToGeminiFormat(request: ChatCompletionRequest): GeminiRequest {\n  const contents: GeminiContent[] = [];\n  let systemInstruction: { parts: Array<{ text: string }> } | undefined;\n\n  for (const message of request.messages) {\n    if (message.role === \"system\") {\n      // Gemini handles system prompts separately\n      const text = typeof message.content === \"string\" ? message.content : \"\";\n      systemInstruction = { parts: [{ text }] };\n    } else {\n      const role = message.role === \"assistant\" ? \"model\" : \"user\";\n      const parts: Array<{ text: string }> = [];\n\n      if (typeof message.content === \"string\") {\n        parts.push({ text: message.content });\n      } else if (Array.isArray(message.content)) {\n        for (const part of message.content) {\n          if (part.type === \"text\" && part.text) {\n            parts.push({ text: part.text });\n          }\n          // Image handling could be added here\n        }\n      } else if (message.content === null) {\n        parts.push({ text: \"\" });\n      }\n\n      if (parts.length > 0) {\n        contents.push({ role, parts });\n      }\n    }\n  }\n\n  const geminiRequest: GeminiRequest = { contents };\n\n  if (systemInstruction) {\n    geminiRequest.systemInstruction = systemInstruction;\n  }\n\n  // Generation config\n  const generationConfig: GeminiRequest[\"generationConfig\"] = {};\n\n  if (request.temperature !== undefined) {\n    generationConfig.temperature = request.temperature;\n  }\n  if (request.top_p !== undefined) {\n    generationConfig.topP = request.top_p;\n  }\n  if (request.max_tokens !== undefined) {\n    generationConfig.maxOutputTokens = request.max_tokens;\n  }\n  if (request.stop) {\n    generationConfig.stopSequences = Array.isArray(request.stop)\n      ? request.stop\n      : [request.stop];\n  }\n\n  if (Object.keys(generationConfig).length > 0) {\n    geminiRequest.generationConfig = generationConfig;\n  }\n\n  return geminiRequest;\n}\n\ninterface GeminiResponse {\n  candidates?: Array<{\n    content?: {\n      parts?: Array<{ text?: string }>;\n      role?: string;\n    };\n    finishReason?: string;\n  }>;\n  usageMetadata?: {\n    promptTokenCount?: number;\n    candidatesTokenCount?: number;\n    totalTokenCount?: number;\n  };\n}\n\nfunction convertToOpenAIFormat(geminiResponse: GeminiResponse, model: string) {\n  const candidate = geminiResponse.candidates?.[0];\n  const content =\n    candidate?.content?.parts?.map((p) => p.text || \"\").join(\"\") || \"\";\n\n  return {\n    id: `chatcmpl-${Date.now()}`,\n    object: \"chat.completion\",\n    created: Math.floor(Date.now() / 1000),\n    model: model.replace(\"models/\", \"\"),\n    choices: [\n      {\n        index: 0,\n        message: {\n          role: \"assistant\",\n          content,\n        },\n        finish_reason: mapFinishReason(candidate?.finishReason),\n      },\n    ],\n    usage: {\n      prompt_tokens: geminiResponse.usageMetadata?.promptTokenCount || 0,\n      completion_tokens:\n        geminiResponse.usageMetadata?.candidatesTokenCount || 0,\n      total_tokens: geminiResponse.usageMetadata?.totalTokenCount || 0,\n    },\n  };\n}\n\nfunction mapFinishReason(reason?: string): string {\n  switch (reason) {\n    case \"STOP\":\n      return \"stop\";\n    case \"MAX_TOKENS\":\n      return \"length\";\n    case \"SAFETY\":\n      return \"content_filter\";\n    case \"RECITATION\":\n      return \"content_filter\";\n    default:\n      return \"stop\";\n  }\n}\n\nfunction transformGeminiStream(\n  input: ReadableStream<Uint8Array>,\n  model: string\n): ReadableStream<Uint8Array> {\n  const decoder = new TextDecoder();\n  const encoder = new TextEncoder();\n  let buffer = \"\";\n\n  return new ReadableStream({\n    async start(controller) {\n      const reader = input.getReader();\n\n      try {\n        while (true) {\n          const { done, value } = await reader.read();\n\n          if (done) {\n            // Send final [DONE] message\n            controller.enqueue(encoder.encode(\"data: [DONE]\\n\\n\"));\n            controller.close();\n            break;\n          }\n\n          buffer += decoder.decode(value, { stream: true });\n\n          // Process SSE events\n          const lines = buffer.split(\"\\n\");\n          buffer = lines.pop() || \"\";\n\n          for (const line of lines) {\n            if (line.startsWith(\"data: \")) {\n              const data = line.slice(6);\n\n              if (data === \"[DONE]\") {\n                controller.enqueue(encoder.encode(\"data: [DONE]\\n\\n\"));\n                continue;\n              }\n\n              try {\n                const geminiChunk = JSON.parse(data) as GeminiResponse;\n                const openaiChunk = convertStreamChunkToOpenAI(\n                  geminiChunk,\n                  model\n                );\n                controller.enqueue(\n                  encoder.encode(`data: ${JSON.stringify(openaiChunk)}\\n\\n`)\n                );\n              } catch {\n                // Skip malformed chunks\n              }\n            }\n          }\n        }\n      } catch (error) {\n        controller.error(error);\n      }\n    },\n  });\n}\n\nfunction convertStreamChunkToOpenAI(\n  geminiChunk: GeminiResponse,\n  model: string\n) {\n  const candidate = geminiChunk.candidates?.[0];\n  const content =\n    candidate?.content?.parts?.map((p) => p.text || \"\").join(\"\") || \"\";\n\n  return {\n    id: `chatcmpl-${Date.now()}`,\n    object: \"chat.completion.chunk\",\n    created: Math.floor(Date.now() / 1000),\n    model: model.replace(\"models/\", \"\"),\n    choices: [\n      {\n        index: 0,\n        delta: {\n          content,\n        },\n        finish_reason: candidate?.finishReason\n          ? mapFinishReason(candidate.finishReason)\n          : null,\n      },\n    ],\n  };\n}\n\n// ============================================\n// ERROR HANDLING\n// ============================================\n\nclass GeminiApiError extends Error {\n  constructor(\n    public status: number,\n    public body: string\n  ) {\n    super(`Gemini API error: ${status}`);\n    this.name = \"GeminiApiError\";\n  }\n}\n\nfunction mapGeminiError(error: GeminiApiError): PluginMappedError {\n  let parsed: { error?: { message?: string; status?: string; code?: number } } =\n    {};\n  try {\n    parsed = JSON.parse(error.body);\n  } catch {\n    // Ignore parse errors\n  }\n\n  const message = parsed.error?.message || error.body;\n\n  switch (error.status) {\n    case 400:\n      return { status: 400, code: \"BAD_REQUEST\", message, retryable: false };\n    case 401:\n      return {\n        status: 401,\n        code: \"UNAUTHORIZED\",\n        message: \"Invalid API key\",\n        retryable: false,\n      };\n    case 403:\n      return { status: 403, code: \"FORBIDDEN\", message, retryable: false };\n    case 404:\n      return { status: 404, code: \"NOT_FOUND\", message, retryable: false };\n    case 429:\n      return { status: 429, code: \"RATE_LIMITED\", message, retryable: true };\n    case 500:\n    case 502:\n    case 503:\n      return {\n        status: error.status,\n        code: \"PROVIDER_ERROR\",\n        message,\n        retryable: true,\n      };\n    default:\n      return {\n        status: error.status,\n        code: \"UNKNOWN\",\n        message,\n        retryable: false,\n      };\n  }\n}\n\n// ============================================\n// PLUGIN IMPLEMENTATION\n// ============================================\n\nconst geminiPlugin: PluginContract = {\n  ...createPluginBase({\n    id: \"llm:gemini\",\n    resourceType: \"llm\",\n    provider: \"gemini\",\n    version: \"1.0.0\",\n    name: \"Google Gemini\",\n    actions: [\"chat.completions\"],\n    supports: {\n      enforcement: [\"model\", \"max_tokens\", \"streaming\"],\n    },\n  }),\n\n  // Extractor reference for enforcement\n  extractors: {\n    \"chat.completions\": {\n      type: \"gemini\",\n    },\n  },\n\n  // Credential schema for UI\n  credentialSchema: {\n    fields: [\n      {\n        name: \"apiKey\",\n        type: \"secret\",\n        label: \"API Key\",\n        description: \"Your Google AI Studio API key\",\n        required: true,\n      },\n      {\n        name: \"baseUrl\",\n        type: \"url\",\n        label: \"Base URL\",\n        description: \"Custom API base URL (optional)\",\n        required: false,\n        default: GEMINI_API_URL,\n      },\n    ],\n  },\n\n  validateAndShape(\n    action: string,\n    input: unknown,\n    constraints: PluginResourceConstraints\n  ): PluginValidationResult {\n    if (action !== \"chat.completions\") {\n      return { valid: false, error: `Unsupported action: ${action}` };\n    }\n\n    // Parse input\n    const parsed = ChatCompletionRequestSchema.safeParse(input);\n    if (!parsed.success) {\n      return {\n        valid: false,\n        error: `Invalid request: ${parsed.error.errors.map((e) => e.message).join(\", \")}`,\n      };\n    }\n\n    const request = parsed.data;\n\n    // Get model name (add models/ prefix if not present)\n    let modelName = request.model;\n    if (!modelName.startsWith(\"models/\")) {\n      modelName = `models/${modelName}`;\n    }\n\n    // Check allowed models (compare without prefix)\n    const allowedModels = constraints.allowedModels ?? DEFAULT_GEMINI_MODELS;\n    const modelWithoutPrefix = modelName.replace(\"models/\", \"\");\n\n    if (\n      !allowedModels.some((m) => m === modelWithoutPrefix || m === modelName)\n    ) {\n      return {\n        valid: false,\n        error: `Model '${request.model}' not allowed. Allowed: ${allowedModels.join(\", \")}`,\n      };\n    }\n\n    // Enforce max tokens\n    const maxTokens = constraints.maxOutputTokens ?? 8192;\n    const requestedTokens = request.max_tokens ?? request.max_completion_tokens;\n\n    if (requestedTokens && requestedTokens > maxTokens) {\n      return {\n        valid: false,\n        error: `max_tokens (${requestedTokens}) exceeds limit (${maxTokens})`,\n      };\n    }\n\n    // Check streaming permission\n    if (request.stream && constraints.allowStreaming === false) {\n      return {\n        valid: false,\n        error: \"Streaming is not allowed for this app\",\n      };\n    }\n\n    // Shape the request\n    const shapedRequest = {\n      ...request,\n      model: modelName,\n      max_tokens: requestedTokens\n        ? Math.min(requestedTokens, maxTokens)\n        : undefined,\n    };\n\n    return { valid: true, shapedInput: shapedRequest };\n  },\n\n  async execute(\n    action: string,\n    shapedInput: unknown,\n    ctx: PluginExecuteContext,\n    options: PluginExecuteOptions\n  ): Promise<PluginExecuteResult> {\n    const request = shapedInput as ChatCompletionRequest & { model: string };\n    const baseUrl = (ctx.config?.baseUrl as string) || GEMINI_API_URL;\n\n    // Convert OpenAI format to Gemini format\n    const geminiRequest = convertToGeminiFormat(request);\n\n    const endpoint = request.stream\n      ? `${baseUrl}/${request.model}:streamGenerateContent?alt=sse&key=${ctx.secret}`\n      : `${baseUrl}/${request.model}:generateContent?key=${ctx.secret}`;\n\n    const response = await fetch(endpoint, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify(geminiRequest),\n      signal: options.signal,\n    });\n\n    if (!response.ok) {\n      const errorBody = await response.text();\n      throw new GeminiApiError(response.status, errorBody);\n    }\n\n    if (request.stream) {\n      // Transform Gemini SSE stream to OpenAI-compatible SSE stream\n      const transformedStream = transformGeminiStream(\n        response.body!,\n        request.model\n      );\n      return {\n        stream: transformedStream,\n        contentType: \"text/event-stream\",\n      };\n    } else {\n      // Transform Gemini response to OpenAI-compatible format\n      const geminiResponse = await response.json();\n      const openaiResponse = convertToOpenAIFormat(\n        geminiResponse,\n        request.model\n      );\n\n      return {\n        response: openaiResponse,\n        contentType: \"application/json\",\n        usage: this.extractUsage(openaiResponse),\n      };\n    }\n  },\n\n  extractUsage(response: unknown): PluginUsageMetrics {\n    const res = response as {\n      usage?: {\n        prompt_tokens?: number;\n        completion_tokens?: number;\n        total_tokens?: number;\n      };\n      model?: string;\n    };\n\n    return {\n      inputTokens: res.usage?.prompt_tokens,\n      outputTokens: res.usage?.completion_tokens,\n      totalTokens: res.usage?.total_tokens,\n      model: res.model,\n    };\n  },\n\n  mapError(error: unknown): PluginMappedError {\n    if (error instanceof GeminiApiError) {\n      return mapGeminiError(error);\n    }\n\n    return {\n      status: 500,\n      code: \"INTERNAL_ERROR\",\n      message: error instanceof Error ? error.message : \"Unknown error\",\n      retryable: false,\n    };\n  },\n};\n\nexport default geminiPlugin;\n\n// Also export named for flexibility\nexport { geminiPlugin };\nexport type { ChatCompletionRequest };\n"],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBAAkB;AAWlB,oBAAiC;AAOjC,IAAM,iBAAiB;AAGvB,IAAM,wBAAwB;AAAA,EAC5B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAMA,IAAM,oBAAoB,aAAE,OAAO;AAAA,EACjC,MAAM,aAAE,KAAK,CAAC,UAAU,QAAQ,aAAa,MAAM,CAAC;AAAA,EACpD,SAAS,aACN,MAAM;AAAA,IACL,aAAE,OAAO;AAAA,IACT,aAAE;AAAA,MACA,aAAE,OAAO;AAAA,QACP,MAAM,aAAE,OAAO;AAAA,QACf,MAAM,aAAE,OAAO,EAAE,SAAS;AAAA,QAC1B,WAAW,aACR,OAAO;AAAA,UACN,KAAK,aAAE,OAAO;AAAA,UACd,QAAQ,aAAE,OAAO,EAAE,SAAS;AAAA,QAC9B,CAAC,EACA,SAAS;AAAA,MACd,CAAC;AAAA,IACH;AAAA,EACF,CAAC,EACA,SAAS;AAAA,EACZ,MAAM,aAAE,OAAO,EAAE,SAAS;AAAA,EAC1B,YAAY,aACT;AAAA,IACC,aAAE,OAAO;AAAA,MACP,IAAI,aAAE,OAAO;AAAA,MACb,MAAM,aAAE,QAAQ,UAAU;AAAA,MAC1B,UAAU,aAAE,OAAO;AAAA,QACjB,MAAM,aAAE,OAAO;AAAA,QACf,WAAW,aAAE,OAAO;AAAA,MACtB,CAAC;AAAA,IACH,CAAC;AAAA,EACH,EACC,SAAS;AAAA,EACZ,cAAc,aAAE,OAAO,EAAE,SAAS;AACpC,CAAC;AAED,IAAM,8BAA8B,aAAE,OAAO;AAAA,EAC3C,OAAO,aAAE,OAAO;AAAA,EAChB,UAAU,aAAE,MAAM,iBAAiB;AAAA,EACnC,aAAa,aAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,SAAS;AAAA,EAC/C,OAAO,aAAE,OAAO,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,SAAS;AAAA,EACzC,GAAG,aAAE,OAAO,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,IAAI,EAAE,EAAE,SAAS;AAAA,EAC5C,QAAQ,aAAE,QAAQ,EAAE,SAAS;AAAA,EAC7B,MAAM,aAAE,MAAM,CAAC,aAAE,OAAO,GAAG,aAAE,MAAM,aAAE,OAAO,CAAC,CAAC,CAAC,EAAE,SAAS;AAAA,EAC1D,YAAY,aAAE,OAAO,EAAE,IAAI,EAAE,SAAS,EAAE,SAAS;AAAA,EACjD,uBAAuB,aAAE,OAAO,EAAE,IAAI,EAAE,SAAS,EAAE,SAAS;AAAA,EAC5D,kBAAkB,aAAE,OAAO,EAAE,IAAI,EAAE,EAAE,IAAI,CAAC,EAAE,SAAS;AAAA,EACrD,mBAAmB,aAAE,OAAO,EAAE,IAAI,EAAE,EAAE,IAAI,CAAC,EAAE,SAAS;AAAA,EACtD,YAAY,aAAE,OAAO,aAAE,OAAO,CAAC,EAAE,SAAS;AAAA,EAC1C,MAAM,aAAE,OAAO,EAAE,SAAS;AAAA,EAC1B,OAAO,aACJ;AAAA,IACC,aAAE,OAAO;AAAA,MACP,MAAM,aAAE,QAAQ,UAAU;AAAA,MAC1B,UAAU,aAAE,OAAO;AAAA,QACjB,MAAM,aAAE,OAAO;AAAA,QACf,aAAa,aAAE,OAAO,EAAE,SAAS;AAAA,QACjC,YAAY,aAAE,OAAO,aAAE,QAAQ,CAAC,EAAE,SAAS;AAAA,MAC7C,CAAC;AAAA,IACH,CAAC;AAAA,EACH,EACC,SAAS;AAAA,EACZ,aAAa,aACV,MAAM;AAAA,IACL,aAAE,QAAQ,MAAM;AAAA,IAChB,aAAE,QAAQ,MAAM;AAAA,IAChB,aAAE,QAAQ,UAAU;AAAA,IACpB,aAAE,OAAO;AAAA,MACP,MAAM,aAAE,QAAQ,UAAU;AAAA,MAC1B,UAAU,aAAE,OAAO,EAAE,MAAM,aAAE,OAAO,EAAE,CAAC;AAAA,IACzC,CAAC;AAAA,EACH,CAAC,EACA,SAAS;AAAA,EACZ,iBAAiB,aACd,OAAO;AAAA,IACN,MAAM,aAAE,KAAK,CAAC,QAAQ,aAAa,CAAC;AAAA,EACtC,CAAC,EACA,SAAS;AAAA,EACZ,MAAM,aAAE,OAAO,EAAE,IAAI,EAAE,SAAS;AAClC,CAAC;AA0BD,SAAS,sBAAsB,SAA+C;AAC5E,QAAM,WAA4B,CAAC;AACnC,MAAI;AAEJ,aAAW,WAAW,QAAQ,UAAU;AACtC,QAAI,QAAQ,SAAS,UAAU;AAE7B,YAAM,OAAO,OAAO,QAAQ,YAAY,WAAW,QAAQ,UAAU;AACrE,0BAAoB,EAAE,OAAO,CAAC,EAAE,KAAK,CAAC,EAAE;AAAA,IAC1C,OAAO;AACL,YAAM,OAAO,QAAQ,SAAS,cAAc,UAAU;AACtD,YAAM,QAAiC,CAAC;AAExC,UAAI,OAAO,QAAQ,YAAY,UAAU;AACvC,cAAM,KAAK,EAAE,MAAM,QAAQ,QAAQ,CAAC;AAAA,MACtC,WAAW,MAAM,QAAQ,QAAQ,OAAO,GAAG;AACzC,mBAAW,QAAQ,QAAQ,SAAS;AAClC,cAAI,KAAK,SAAS,UAAU,KAAK,MAAM;AACrC,kBAAM,KAAK,EAAE,MAAM,KAAK,KAAK,CAAC;AAAA,UAChC;AAAA,QAEF;AAAA,MACF,WAAW,QAAQ,YAAY,MAAM;AACnC,cAAM,KAAK,EAAE,MAAM,GAAG,CAAC;AAAA,MACzB;AAEA,UAAI,MAAM,SAAS,GAAG;AACpB,iBAAS,KAAK,EAAE,MAAM,MAAM,CAAC;AAAA,MAC/B;AAAA,IACF;AAAA,EACF;AAEA,QAAM,gBAA+B,EAAE,SAAS;AAEhD,MAAI,mBAAmB;AACrB,kBAAc,oBAAoB;AAAA,EACpC;AAGA,QAAM,mBAAsD,CAAC;AAE7D,MAAI,QAAQ,gBAAgB,QAAW;AACrC,qBAAiB,cAAc,QAAQ;AAAA,EACzC;AACA,MAAI,QAAQ,UAAU,QAAW;AAC/B,qBAAiB,OAAO,QAAQ;AAAA,EAClC;AACA,MAAI,QAAQ,eAAe,QAAW;AACpC,qBAAiB,kBAAkB,QAAQ;AAAA,EAC7C;AACA,MAAI,QAAQ,MAAM;AAChB,qBAAiB,gBAAgB,MAAM,QAAQ,QAAQ,IAAI,IACvD,QAAQ,OACR,CAAC,QAAQ,IAAI;AAAA,EACnB;AAEA,MAAI,OAAO,KAAK,gBAAgB,EAAE,SAAS,GAAG;AAC5C,kBAAc,mBAAmB;AAAA,EACnC;AAEA,SAAO;AACT;AAiBA,SAAS,sBAAsB,gBAAgC,OAAe;AAC5E,QAAM,YAAY,eAAe,aAAa,CAAC;AAC/C,QAAM,UACJ,WAAW,SAAS,OAAO,IAAI,CAAC,MAAM,EAAE,QAAQ,EAAE,EAAE,KAAK,EAAE,KAAK;AAElE,SAAO;AAAA,IACL,IAAI,YAAY,KAAK,IAAI,CAAC;AAAA,IAC1B,QAAQ;AAAA,IACR,SAAS,KAAK,MAAM,KAAK,IAAI,IAAI,GAAI;AAAA,IACrC,OAAO,MAAM,QAAQ,WAAW,EAAE;AAAA,IAClC,SAAS;AAAA,MACP;AAAA,QACE,OAAO;AAAA,QACP,SAAS;AAAA,UACP,MAAM;AAAA,UACN;AAAA,QACF;AAAA,QACA,eAAe,gBAAgB,WAAW,YAAY;AAAA,MACxD;AAAA,IACF;AAAA,IACA,OAAO;AAAA,MACL,eAAe,eAAe,eAAe,oBAAoB;AAAA,MACjE,mBACE,eAAe,eAAe,wBAAwB;AAAA,MACxD,cAAc,eAAe,eAAe,mBAAmB;AAAA,IACjE;AAAA,EACF;AACF;AAEA,SAAS,gBAAgB,QAAyB;AAChD,UAAQ,QAAQ;AAAA,IACd,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT;AACE,aAAO;AAAA,EACX;AACF;AAEA,SAAS,sBACP,OACA,OAC4B;AAC5B,QAAM,UAAU,IAAI,YAAY;AAChC,QAAM,UAAU,IAAI,YAAY;AAChC,MAAI,SAAS;AAEb,SAAO,IAAI,eAAe;AAAA,IACxB,MAAM,MAAM,YAAY;AACtB,YAAM,SAAS,MAAM,UAAU;AAE/B,UAAI;AACF,eAAO,MAAM;AACX,gBAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAE1C,cAAI,MAAM;AAER,uBAAW,QAAQ,QAAQ,OAAO,kBAAkB,CAAC;AACrD,uBAAW,MAAM;AACjB;AAAA,UACF;AAEA,oBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAGhD,gBAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,mBAAS,MAAM,IAAI,KAAK;AAExB,qBAAW,QAAQ,OAAO;AACxB,gBAAI,KAAK,WAAW,QAAQ,GAAG;AAC7B,oBAAM,OAAO,KAAK,MAAM,CAAC;AAEzB,kBAAI,SAAS,UAAU;AACrB,2BAAW,QAAQ,QAAQ,OAAO,kBAAkB,CAAC;AACrD;AAAA,cACF;AAEA,kBAAI;AACF,sBAAM,cAAc,KAAK,MAAM,IAAI;AACnC,sBAAM,cAAc;AAAA,kBAClB;AAAA,kBACA;AAAA,gBACF;AACA,2BAAW;AAAA,kBACT,QAAQ,OAAO,SAAS,KAAK,UAAU,WAAW,CAAC;AAAA;AAAA,CAAM;AAAA,gBAC3D;AAAA,cACF,QAAQ;AAAA,cAER;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF,SAAS,OAAO;AACd,mBAAW,MAAM,KAAK;AAAA,MACxB;AAAA,IACF;AAAA,EACF,CAAC;AACH;AAEA,SAAS,2BACP,aACA,OACA;AACA,QAAM,YAAY,YAAY,aAAa,CAAC;AAC5C,QAAM,UACJ,WAAW,SAAS,OAAO,IAAI,CAAC,MAAM,EAAE,QAAQ,EAAE,EAAE,KAAK,EAAE,KAAK;AAElE,SAAO;AAAA,IACL,IAAI,YAAY,KAAK,IAAI,CAAC;AAAA,IAC1B,QAAQ;AAAA,IACR,SAAS,KAAK,MAAM,KAAK,IAAI,IAAI,GAAI;AAAA,IACrC,OAAO,MAAM,QAAQ,WAAW,EAAE;AAAA,IAClC,SAAS;AAAA,MACP;AAAA,QACE,OAAO;AAAA,QACP,OAAO;AAAA,UACL;AAAA,QACF;AAAA,QACA,eAAe,WAAW,eACtB,gBAAgB,UAAU,YAAY,IACtC;AAAA,MACN;AAAA,IACF;AAAA,EACF;AACF;AAMA,IAAM,iBAAN,cAA6B,MAAM;AAAA,EACjC,YACS,QACA,MACP;AACA,UAAM,qBAAqB,MAAM,EAAE;AAH5B;AACA;AAGP,SAAK,OAAO;AAAA,EACd;AACF;AAEA,SAAS,eAAe,OAA0C;AAChE,MAAI,SACF,CAAC;AACH,MAAI;AACF,aAAS,KAAK,MAAM,MAAM,IAAI;AAAA,EAChC,QAAQ;AAAA,EAER;AAEA,QAAM,UAAU,OAAO,OAAO,WAAW,MAAM;AAE/C,UAAQ,MAAM,QAAQ;AAAA,IACpB,KAAK;AACH,aAAO,EAAE,QAAQ,KAAK,MAAM,eAAe,SAAS,WAAW,MAAM;AAAA,IACvE,KAAK;AACH,aAAO;AAAA,QACL,QAAQ;AAAA,QACR,MAAM;AAAA,QACN,SAAS;AAAA,QACT,WAAW;AAAA,MACb;AAAA,IACF,KAAK;AACH,aAAO,EAAE,QAAQ,KAAK,MAAM,aAAa,SAAS,WAAW,MAAM;AAAA,IACrE,KAAK;AACH,aAAO,EAAE,QAAQ,KAAK,MAAM,aAAa,SAAS,WAAW,MAAM;AAAA,IACrE,KAAK;AACH,aAAO,EAAE,QAAQ,KAAK,MAAM,gBAAgB,SAAS,WAAW,KAAK;AAAA,IACvE,KAAK;AAAA,IACL,KAAK;AAAA,IACL,KAAK;AACH,aAAO;AAAA,QACL,QAAQ,MAAM;AAAA,QACd,MAAM;AAAA,QACN;AAAA,QACA,WAAW;AAAA,MACb;AAAA,IACF;AACE,aAAO;AAAA,QACL,QAAQ,MAAM;AAAA,QACd,MAAM;AAAA,QACN;AAAA,QACA,WAAW;AAAA,MACb;AAAA,EACJ;AACF;AAMA,IAAM,eAA+B;AAAA,EACnC,OAAG,gCAAiB;AAAA,IAClB,IAAI;AAAA,IACJ,cAAc;AAAA,IACd,UAAU;AAAA,IACV,SAAS;AAAA,IACT,MAAM;AAAA,IACN,SAAS,CAAC,kBAAkB;AAAA,IAC5B,UAAU;AAAA,MACR,aAAa,CAAC,SAAS,cAAc,WAAW;AAAA,IAClD;AAAA,EACF,CAAC;AAAA;AAAA,EAGD,YAAY;AAAA,IACV,oBAAoB;AAAA,MAClB,MAAM;AAAA,IACR;AAAA,EACF;AAAA;AAAA,EAGA,kBAAkB;AAAA,IAChB,QAAQ;AAAA,MACN;AAAA,QACE,MAAM;AAAA,QACN,MAAM;AAAA,QACN,OAAO;AAAA,QACP,aAAa;AAAA,QACb,UAAU;AAAA,MACZ;AAAA,MACA;AAAA,QACE,MAAM;AAAA,QACN,MAAM;AAAA,QACN,OAAO;AAAA,QACP,aAAa;AAAA,QACb,UAAU;AAAA,QACV,SAAS;AAAA,MACX;AAAA,IACF;AAAA,EACF;AAAA,EAEA,iBACE,QACA,OACA,aACwB;AACxB,QAAI,WAAW,oBAAoB;AACjC,aAAO,EAAE,OAAO,OAAO,OAAO,uBAAuB,MAAM,GAAG;AAAA,IAChE;AAGA,UAAM,SAAS,4BAA4B,UAAU,KAAK;AAC1D,QAAI,CAAC,OAAO,SAAS;AACnB,aAAO;AAAA,QACL,OAAO;AAAA,QACP,OAAO,oBAAoB,OAAO,MAAM,OAAO,IAAI,CAAC,MAAM,EAAE,OAAO,EAAE,KAAK,IAAI,CAAC;AAAA,MACjF;AAAA,IACF;AAEA,UAAM,UAAU,OAAO;AAGvB,QAAI,YAAY,QAAQ;AACxB,QAAI,CAAC,UAAU,WAAW,SAAS,GAAG;AACpC,kBAAY,UAAU,SAAS;AAAA,IACjC;AAGA,UAAM,gBAAgB,YAAY,iBAAiB;AACnD,UAAM,qBAAqB,UAAU,QAAQ,WAAW,EAAE;AAE1D,QACE,CAAC,cAAc,KAAK,CAAC,MAAM,MAAM,sBAAsB,MAAM,SAAS,GACtE;AACA,aAAO;AAAA,QACL,OAAO;AAAA,QACP,OAAO,UAAU,QAAQ,KAAK,2BAA2B,cAAc,KAAK,IAAI,CAAC;AAAA,MACnF;AAAA,IACF;AAGA,UAAM,YAAY,YAAY,mBAAmB;AACjD,UAAM,kBAAkB,QAAQ,cAAc,QAAQ;AAEtD,QAAI,mBAAmB,kBAAkB,WAAW;AAClD,aAAO;AAAA,QACL,OAAO;AAAA,QACP,OAAO,eAAe,eAAe,oBAAoB,SAAS;AAAA,MACpE;AAAA,IACF;AAGA,QAAI,QAAQ,UAAU,YAAY,mBAAmB,OAAO;AAC1D,aAAO;AAAA,QACL,OAAO;AAAA,QACP,OAAO;AAAA,MACT;AAAA,IACF;AAGA,UAAM,gBAAgB;AAAA,MACpB,GAAG;AAAA,MACH,OAAO;AAAA,MACP,YAAY,kBACR,KAAK,IAAI,iBAAiB,SAAS,IACnC;AAAA,IACN;AAEA,WAAO,EAAE,OAAO,MAAM,aAAa,cAAc;AAAA,EACnD;AAAA,EAEA,MAAM,QACJ,QACA,aACA,KACA,SAC8B;AAC9B,UAAM,UAAU;AAChB,UAAM,UAAW,IAAI,QAAQ,WAAsB;AAGnD,UAAM,gBAAgB,sBAAsB,OAAO;AAEnD,UAAM,WAAW,QAAQ,SACrB,GAAG,OAAO,IAAI,QAAQ,KAAK,sCAAsC,IAAI,MAAM,KAC3E,GAAG,OAAO,IAAI,QAAQ,KAAK,wBAAwB,IAAI,MAAM;AAEjE,UAAM,WAAW,MAAM,MAAM,UAAU;AAAA,MACrC,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU,aAAa;AAAA,MAClC,QAAQ,QAAQ;AAAA,IAClB,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,YAAM,IAAI,eAAe,SAAS,QAAQ,SAAS;AAAA,IACrD;AAEA,QAAI,QAAQ,QAAQ;AAElB,YAAM,oBAAoB;AAAA,QACxB,SAAS;AAAA,QACT,QAAQ;AAAA,MACV;AACA,aAAO;AAAA,QACL,QAAQ;AAAA,QACR,aAAa;AAAA,MACf;AAAA,IACF,OAAO;AAEL,YAAM,iBAAiB,MAAM,SAAS,KAAK;AAC3C,YAAM,iBAAiB;AAAA,QACrB;AAAA,QACA,QAAQ;AAAA,MACV;AAEA,aAAO;AAAA,QACL,UAAU;AAAA,QACV,aAAa;AAAA,QACb,OAAO,KAAK,aAAa,cAAc;AAAA,MACzC;AAAA,IACF;AAAA,EACF;AAAA,EAEA,aAAa,UAAuC;AAClD,UAAM,MAAM;AASZ,WAAO;AAAA,MACL,aAAa,IAAI,OAAO;AAAA,MACxB,cAAc,IAAI,OAAO;AAAA,MACzB,aAAa,IAAI,OAAO;AAAA,MACxB,OAAO,IAAI;AAAA,IACb;AAAA,EACF;AAAA,EAEA,SAAS,OAAmC;AAC1C,QAAI,iBAAiB,gBAAgB;AACnC,aAAO,eAAe,KAAK;AAAA,IAC7B;AAEA,WAAO;AAAA,MACL,QAAQ;AAAA,MACR,MAAM;AAAA,MACN,SAAS,iBAAiB,QAAQ,MAAM,UAAU;AAAA,MAClD,WAAW;AAAA,IACb;AAAA,EACF;AACF;AAEA,IAAO,gBAAQ;","names":[]}