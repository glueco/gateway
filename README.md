# Glueco Gateway

<p align="center">
  <img src="https://img.shields.io/badge/version-0.1.0-blue.svg" alt="Version">
  <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg" alt="Node Version">
</p>

<p align="center">
  <strong>ğŸ” Safely share your API keys with applications â€” without ever exposing them.</strong>
</p>

<p align="center">
  <a href="#the-problem">The Problem</a> â€¢
  <a href="#the-solution">The Solution</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#demo">Try Demo</a> â€¢
  <a href="./docs/ADMIN_GUIDE.md">Deploy Guide</a>
</p>

---

## The Problem

**AI apps are cheap to build, expensive to run.**

It's easy to ship an AI feature. It's hard to ship an AI _product_.

If your app calls OpenAI, Groq, Gemini, or Resend, _someone_ must provide paid API keys. That creates a brutal tradeoff:

### Option 1: Use Your Own Keys

You become the payer. Every user request costs you money. Open-source projects and indie apps can't sustainably subsidize usage.

### Option 2: Ask Users for Their Keys

Users must trust you with their secrets. Keys can be leaked, abused, overused, or copied. Users get no spend caps, no visibility, and no reliable kill-switch.

---

This is why many promising AI tools either:

- ğŸ’³ Hide behind subscriptions (pricing you out of experimentation)
- ğŸ™ Ask you to paste an API key and "trust us"

---

## The Solution

**Glueco replaces "trust us with your key" with "connect your key safely."**

Your Gateway acts as a **secure proxy** between applications and your API providers. You store your API keys once, then grant apps **controlled, time-limited access** through the gateway.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your App  â”‚ â”€â”€â”€â”€â”€â”€â–¶â”‚  Your Gateway   â”‚ â”€â”€â”€â”€â”€â”€â–¶â”‚  OpenAI/Groq/   â”‚
â”‚             â”‚â—€â”€â”€â”€â”€â”€â”€ â”‚  (with your     â”‚â—€â”€â”€â”€â”€â”€â”€ â”‚  Gemini/etc     â”‚
â”‚  (no keys)  â”‚        â”‚   API keys)     â”‚        â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What You Get

- ğŸ” **Your keys stay yours** â€” Apps never see or touch your API keys
- â±ï¸ **Time-limited access** â€” Permissions auto-expire (1 hour, 1 day, 1 week...)
- ğŸ’¸ **Spend control** â€” Rate limits, quotas, and token budgets per app
- ğŸ“Š **Full visibility** â€” See exactly how each app uses your resources
- âš¡ **Instant revoke** â€” Kill access anytime with one click

---

## Features

### ï¿½ï¸ Cryptographic Authentication

PoP (Proof-of-Possession) ensures only authorized apps can make requests. No shared secrets, no leaked tokens.

### ğŸ›ï¸ Fine-Grained Control

- **Model restrictions** â€” Allow only specific AI models
- **Rate limits** â€” Requests per minute/hour
- **Quotas** â€” Daily/monthly request caps
- **Token budgets** â€” Limit LLM token usage

### ğŸ”Œ Multi-Provider Support

One gateway, many providers:

- **LLM**: OpenAI, Groq, Google Gemini
- **Email**: Resend
- **Extensible**: Custom plugins easy to create

---

## How It Works

### 1. Deploy Your Gateway

One-click deploy to Vercel with Neon (PostgreSQL) and Upstash (Redis).

### 2. Add Your API Keys

Securely store keys for OpenAI, Groq, Gemini, Resend, etc.

### 3. Generate Pairing Strings

Create one-time pairing strings (valid 10 minutes) for apps you want to connect.

### 4. Approve Access Requests

When an app connects, review and approve what resources it can access, for how long, with what limits.

### 5. Monitor Usage

Watch real-time usage stats. Revoke access anytime.

---

## Quick Start

### Deploy to Vercel (Recommended)

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/glueco/gateway)

See the [Admin Deployment Guide](./docs/ADMIN_GUIDE.md) for detailed setup instructions.

### Local Development

```bash
# Clone repository
git clone https://github.com/glueco/gateway.git
cd gateway

# Install dependencies
npm install

# Set up environment (copy and edit .env)
cd apps/proxy
cp .env.example .env

# Run database migrations
npx prisma migrate dev

# Start development server
npm run dev
```

---

## Demo

Try the gateway with our demo application:

ğŸ”— **Demo App**: [demo-target-app.vercel.app](https://demo-target-app.vercel.app)

The demo app demonstrates:

- Connecting to a gateway using pairing strings
- Making authenticated API requests
- Testing LLM endpoints through the proxy

---

## For App Developers

### Using the SDK

Install the SDK in your application:

```bash
npm install @glueco/sdk
```

Connect and make requests:

```typescript
import { GatewayClient, FileKeyStorage, FileConfigStorage } from "@glueco/sdk";

const client = new GatewayClient({
  keyStorage: new FileKeyStorage("./.gateway/keys.json"),
  configStorage: new FileConfigStorage("./.gateway/config.json"),
});

// Connect using a pairing string from the gateway admin
await client.connect(pairingString, {
  app: {
    name: "My AI App",
    description: "An app that uses AI",
    homepage: "https://myapp.com",
  },
  permissions: [{ resourceId: "llm:groq", actions: ["chat.completions"] }],
  duration: { type: "preset", preset: "1_hour" },
});

// Make requests (keys are NEVER in your app)
const transport = await client.getTransport();
const response = await transport.fetch("/r/llm/groq/v1/chat/completions", {
  method: "POST",
  body: JSON.stringify({
    model: "llama-3.3-70b-versatile",
    messages: [{ role: "user", content: "Hello!" }],
  }),
});
```

### Using with OpenAI SDK

The gateway is OpenAI-compatible, so you can use the official OpenAI SDK:

```typescript
import OpenAI from "openai";

const proxyUrl = await client.getProxyUrl();
const gatewayFetch = await client.getFetch();

const openai = new OpenAI({
  apiKey: "unused", // The gateway handles auth
  baseURL: `${proxyUrl}/r/llm/groq`,
  fetch: gatewayFetch,
});

const completion = await openai.chat.completions.create({
  model: "llama-3.3-70b-versatile",
  messages: [{ role: "user", content: "Hello!" }],
});
```

---

## Supported Resources

| Resource ID   | Provider | Description         |
| ------------- | -------- | ------------------- |
| `llm:openai`  | OpenAI   | GPT-4, GPT-3.5      |
| `llm:groq`    | Groq     | Llama 3.x, Mixtral  |
| `llm:gemini`  | Google   | Gemini 1.5/2.0      |
| `mail:resend` | Resend   | Transactional email |

---

## Documentation

| Document                                             | Description                    |
| ---------------------------------------------------- | ------------------------------ |
| [Admin Guide](./docs/ADMIN_GUIDE.md)                 | Deploy and manage your gateway |
| [Developer Guide](./docs/DEVELOPER_GUIDE.md)         | Build apps with the SDK        |
| [Adding Plugins](./docs/ADDING_PLUGINS.md)           | Enable resource plugins        |
| [Plugin Development](./docs/PACKAGE_ARCHITECTURE.md) | Create custom plugins          |
| [API Reference](./docs/API_REFERENCE.md)             | Gateway API endpoints          |

---

## Plugin Architecture

Glueco Gateway uses a **plug-and-play plugin system**. Each provider (OpenAI, Groq, Gemini, Resend) is a self-contained plugin package that can be enabled or disabled independently.

### How Plugins Work

- **Modular by design** â€” Add or remove providers without touching core gateway code
- **Dual-entrypoint** â€” Each plugin has `/proxy` (server-side) and `/client` (SDK) exports
- **Schema-first enforcement** â€” Plugins define validation and policy rules declaratively
- **Easy to extend** â€” Create custom plugins for any API using the template

### Enabling Plugins

Edit `proxy.plugins.ts` at the root:

```typescript
export default {
  "llm:groq": true,
  "llm:openai": true,
  "llm:gemini": true,
  "mail:resend": true,
};
```

â†’ See [Package Architecture](./docs/PACKAGE_ARCHITECTURE.md) for creating custom plugins.

---

## Project Structure

```
â”œâ”€â”€ apps/proxy/           # Next.js gateway application
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ sdk/              # Client SDK for apps
â”‚   â”œâ”€â”€ shared/           # Shared types and contracts
â”‚   â”œâ”€â”€ plugin-llm-*/     # LLM provider plugins
â”‚   â””â”€â”€ plugin-mail-*/    # Email provider plugins
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ demo-target-app/  # Demo application
â””â”€â”€ docs/                 # Documentation
```

---

## Contributing

We welcome contributions! See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

---

## Security

Found a vulnerability? Please report it privately to dev.umernisar@gmail.com .

---

## License

MIT License - see [LICENSE](./LICENSE) for details.

---

<p align="center">
  Built with â¤ï¸ for developers who value security and control.
</p>
